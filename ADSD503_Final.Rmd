---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

## Data preprocessing

```{r}
## Load and inspect data 

# Load dataset with NA encoded as '?'
df <- read.csv("~/Downloads/heart+disease/processed.cleveland.data", 
               header = FALSE, na.strings = "?")

# Assign column names based on UCI documentation
colnames(df) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
                  "thalach", "exang", "oldpeak", "slope", "ca", "thal", "target")

# View structure and summary
str(df)
summary(df)
```

### Handle missing data

```{r}
# Count missing values per column
sapply(df, function(x) sum(is.na(x)))

# Define mode imputation function
impute_mode <- function(x) {
  ux <- unique(x[!is.na(x)])
  ux[which.max(tabulate(match(x, ux)))]
}

# Impute 'ca' and 'thal' (categorical variables with missing values)
df$ca <- ifelse(is.na(df$ca), impute_mode(df$ca), df$ca)
df$thal <- ifelse(is.na(df$thal), impute_mode(df$thal), df$thal)
```

```{r}
# Binarize the 'target' variable: 0 = No Disease, 1â€“4 = Disease
df$target <- ifelse(df$target == 0, 0, 1)
df$target <- factor(df$target, levels = c(0, 1), labels = c("No Disease", "Disease"))
```

```{r}
# Normalize numerical features

library(caret)

# Identify numeric columns
num_vars <- c("age", "trestbps", "chol", "thalach", "oldpeak")

# Apply standardization (center + scale)
preproc <- preProcess(df[, num_vars], method = c("center", "scale"))
df[, num_vars] <- predict(preproc, df[, num_vars])

# Confirm structure and summary statistics post-processing
str(df)
summary(df)
```

## Exploratory Data Analysis (EDA)

```{r}
summary(df)
str(df)
```

```{r}
# Missing values visualization
library(VIM)
aggr(df, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE)
```

```{r}
# Distributions of numeric variables
library(ggplot2)
ggplot(df, aes(x = age)) + 
  geom_histogram(bins = 30, fill = "steelblue", color = "white")
```

```{r}
# Distribution of key numeric variables
ggplot(df, aes(x = age)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(title = "Age Distribution", x = "Age", y = "Count")

ggplot(df, aes(x = chol)) +
  geom_histogram(bins = 30, fill = "darkgreen", color = "white") +
  labs(title = "Cholesterol Distribution", x = "Cholesterol", y = "Count")

ggplot(df, aes(x = thalach)) +
  geom_histogram(bins = 30, fill = "purple", color = "white") +
  labs(title = "Max Heart Rate Distribution", x = "thalach", y = "Count")

# Target variable distribution
table(df$target)
ggplot(df, aes(x = factor(target))) +
  geom_bar(fill = "coral") +
  labs(title = "Heart Disease Outcome Distribution", x = "Target (0 = No, 1 = Yes)", y = "Count")

# Boxplots of numeric variables by target
ggplot(df, aes(x = factor(target), y = age)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Age by Heart Disease Status", x = "Target", y = "Age")

ggplot(df, aes(x = factor(target), y = thalach)) +
  geom_boxplot(fill = "lightpink") +
  labs(title = "Max Heart Rate by Heart Disease Status", x = "Target", y = "thalach")

# Correlation heatmap of numeric variables
numeric_vars <- df %>%
  select_if(is.numeric)

cor_matrix <- cor(numeric_vars, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8)
```

## Train/Test Split and Model Building

```{r}
# Ensure target is a factor
df$target <- as.factor(df$target)

# Set seed for reproducibility
set.seed(123)

# Split data: 70% training, 30% testing
trainIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train <- df[trainIndex, ]
test <- df[-trainIndex, ]
```

### Logisitc regression model

```{r}
# Fit logistic regression model
log_model <- glm(target ~ ., data = train, family = binomial)

# Predict probabilities on the test set
log_probs <- predict(log_model, newdata = test, type = "response")

# Convert probabilities to class predictions (threshold = 0.5)
log_preds <- ifelse(log_probs > 0.5, "1", "0")

# Ensure both predicted and actual values are factors with the same levels
log_preds <- factor(log_preds, levels = c("0", "1"))
actual <- factor(test$target, levels = c("0", "1"))

# Generate confusion matrix
library(caret)
confusionMatrix(log_preds, actual)
```

### Decision tree model

```{r}
### Decision Tree Model

# Load required package
library(rpart)

# Fit decision tree model
tree_model <- rpart(target ~ ., data = train, method = "class")

# Predict class labels on test set
tree_preds <- predict(tree_model, newdata = test, type = "class")

# Convert predicted and actual labels to factors with consistent levels
tree_preds <- factor(tree_preds, levels = c("0", "1"))
actual <- factor(test$target, levels = c("0", "1"))

# Evaluate using confusion matrix
library(caret)
confusionMatrix(tree_preds, actual)
```

### Random Forest Model

```{r}
# Random Forest
rf_model <- randomForest(target ~ ., data = train, ntree = 100, importance = TRUE)

# Predict
rf_preds <- predict(rf_model, test)

# Evaluation
confusionMatrix(rf_preds, test$target)

# Variable importance plot
varImpPlot(rf_model)
```
